I.	Introduction and Background of the Technology topic: Data Science
Data science is an interdisciplinary field that combines scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It involves various techniques and approaches, including data analysis, statistics, machine learning, data mining, and visualization, to discover patterns, make predictions, and derive meaningful information from large and complex datasets.
Since the early 1960s, when it was often used interchangeably with "computer science," the term "data science" has been in use. Later, the phrase was clarified to refer to a survey of data processing techniques applied in a variety of applications. William S. Cleveland used the phrase "data science" in 2001 to describe a distinct field of study. In a 2012 article from the Harvard Business Review, the position of data scientist was referred to as the "sexiest job of the 21st century."
One of the major components or elements of Data science is the ‘Data’ itself, but what do we mean when we say data? And how we can differentiate this to an information? A collection of unique facts or statistics is referred to as data. Text, observations, figures, pictures, numbers, graphs, and symbols are all examples of data. Data may consist of specific costs, weights, addresses, names, ages, temperatures, dates, or distances, for instance. Data is a basic type of knowledge and has no meaning or use by itself. In other words, facts cannot be meaningful without interpretation. Before being evaluated, organized, and interpreted, data can appear simple or even useless. There are two main types of data, the qualitative and quantitative data. Qualitative data is descriptive but non-numerical, like name, sex, or eye color, while quantitative data is in numerical form, like weight, volume, or cost of an item. 

IV. Presentation of chosen technology
Uses and functions:
 Advanced machine learning and data analytics are changing the healthcare sector. Data science applications in healthcare are extensive, ranging from patient care to operations and medications. Here are some of the data science applications in medical field: 
•	Discovering drugs: The foundation for artificial intelligence-assisted medication synthesis is what data science contributes most to the pharmaceutical sector. Compounds are created that address the statistical association between the attributes using mutation profiling and patient metadata.  
•	Tracking Patient Health and Wearables: Data science is fortunate to benefit from the modern Internet of Things (IoT) phenomenon, which guarantees maximal connectivity. Now that this technology is used in medicine, it can aid in keeping track of patients' health. Nowadays, people track and manage their health with smartwatches and fitness trackers. Furthermore, if given access, a doctor can monitor the patient's condition using these wearable sensor devices and, in severe circumstances, remotely treat the patient.  
•	Predictive Analytics: An analytical predictive model makes use of past data, extracts patterns from the data, and makes precise forecasts. The information could include everything from a patient's body temperature and blood pressure to sugar level. Every data piece is correlated and linked to symptoms, behaviors, and diseases via predictive models in data science. This makes it possible to determine the severity of the damage caused by a disease and the best course of action.

When we say Data Science, it is associated with the Hadoop ecosystem. But what is Hadoop ecosystem? How it became associated with Data Science and such Big data? A platform or collection of tools called the Hadoop Ecosystem offers a few services to address big data issues. Along with different commercial products and solutions, it also includes Apache projects. Hadoop is made up of four main components, i.e., Hadoop Common, HDFS, MapReduce, YARN, and. Most of the available resources are used to strengthen or support these important components. Together, these instruments offer services like data storage, analysis, and maintenance, among other things. 
•	HDFS: Hadoop Distributed File System – In order to retain the information in the form of log files, HDFS, the core component of the Hadoop ecosystem, oversees storing enormous data sets of structured or unstructured data across many nodes. Name node and Data node are the two main parts of HDFS.
•	MapReduce: Programming based Data Processing – MapReduce enables the transfer of processing logic and aids in the creation of applications that reduce large data sets to manageable ones using distributed and parallel algorithms. 

•	YARN: Yet Another Resource Negotiator – As its name suggests, Yet Another Resource Negotiator (YARN) is responsible for assisting in the management of resources amongst clusters. It manages scheduling and resource allocation for the Hadoop System, to put it briefly. It is consisting of three main parts, namely, Resource Director, Manager of Nodes, and Application Supervisor. 

VI. Summary
	Our research interests are in Data Science, Big Data, and Hadoop System with a particular emphasis on the health care field. The objectives of our research are to improve the understanding about Data Science, the difference between data and information, nature and components of big data and the connection of Hadoop System in Data Science itself. This study also focuses on the implications of Data Science in healthcare. 
	Data science is an interdisciplinary field that combines scientific methods, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It involves various techniques and approaches, including data analysis, statistics, machine learning, data mining, and visualization, to discover patterns, make predictions, and derive meaningful information from large and complex datasets.
	The difference of Data to information is that data are raw facts and gained knowledge through study, while the information is a processed form of data in which facts were put into context. 
Data science encompasses the entire data lifecycle, including data collection, data cleaning and preprocessing, data storage and management, exploratory data analysis, modeling, evaluation, and interpretation of results.
A platform or collection of tools called the Hadoop Ecosystem offers a few services to address big data issues. Hadoop Ecosystem has four common components; HDFS: Hadoop Distributed File System , MapReduce: Programming based Data Processing , and YARN: Yet Another Resource Negotiator.
